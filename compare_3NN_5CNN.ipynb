{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5層CNN(Convolutional Neural Network)と3層NN(Neural Network)の精度比較\n",
    "\n",
    "本プログラムの実行によって同ディレクリ上に「result」フォルダが作成され，グラフが保存される．\n",
    "\n",
    "また，CUDAが利用可能な場合，本プログラムの学習はGPUで計算される．動作確認した環境では実行後もGPUのメモリは開放されなかった．このような問題が生じた場合，プログラム実行後にツールバー>File>Close and Halt 等で本プログラムを終了することでメモリが開放される．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # torchモジュール のインポート\n",
    "import torchvision # torchvisionモジュール のインポート\n",
    "import torch.nn as nn # torchのニューラルネットモジュールをnnと名付けインポート\n",
    "import torch.nn.functional as F # torchのニューラルネット関数をFと名付けてインポート\n",
    "import torch.optim as optim # torchの最適化モジュールをoptimと名付けてインポート\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph描画クラス\n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        # ----ユーザー設定値----\n",
    "        self.count = 1  # 保存画像のナンバリング初期値\n",
    "        self.fontsize = \"small\"  # 散布図のテキストのフォントサイズの設定   x0.833 相対的なサイズ\n",
    "        self.markers = [\".\", \"v\", \"x\", \"1\", \",\"]  # 近似手法の数だけ，マーカーを設定\n",
    "        self.lineStyle = [\"solid\", \"dashed\", \"dotted\", \"solid\", \"dashed\", \"dotted\"]\n",
    "        self.saveDirectory = \"result/\"  # 保存するディレクトリを指定\n",
    "        if not os.path.exists(self.saveDirectory):  # ディレクトリが存在しない場合\n",
    "            os.makedirs(self.saveDirectory)  # ディレクトリを作成\n",
    "\n",
    "    # 散布図作成・保存メソッド(marker only)\n",
    "    def scatterDraw(self, scatterLabels, figName, logFlag, *args):  #\n",
    "        # scatterLabels:グラフタイトル,x軸タイトル、y軸タイトル, figName：参照メソッドに関連する名前, logFlag:対数グラフ化のフラグ\n",
    "        # args:(各次元のlogデータ,timeデータ,手法名)のデータセット\n",
    "\n",
    "        # ---グラフ設定----\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 9))  # 拡張性確保のためにsubplotで生成．\n",
    "        plt.subplots_adjust(bottom=0.15)  # グラフの下部空白を拡張\n",
    "\n",
    "        # ---対数グラフ化----\n",
    "        if logFlag:\n",
    "            ax.set_yscale('log')\n",
    "            ax.set_xscale('log')\n",
    "\n",
    "        # ----グラフ作成-----\n",
    "        # グラフに写像するデータの種類分だけループ\n",
    "        for i in range(len(args)):\n",
    "            ax.scatter(args[i][0], args[i][1], label=args[i][2], marker=self.markers[i])  # 散布図を作成\n",
    "        ax.set_title(scatterLabels[0], y=-.2)  # タイトル設定、枠外下部に来るように調整\n",
    "        ax.set_xlabel(scatterLabels[1])  # x軸ラベルの設定、枠外下部に来るように調整\n",
    "        ax.set_ylabel(scatterLabels[2])  # y軸ラベルの設定、枠外左部に来るように調整\n",
    "        plt.grid()  # グリッドを追加\n",
    "#        ax.legend(loc='lower right')  # 凡例の位置を設定\n",
    "        # plt.show()\n",
    "\n",
    "        # ---グラフの保存---\n",
    "        fig.savefig(f\"{self.saveDirectory}scatter{self.count}_{figName}.png\")  # 画像の保存\n",
    "        plt.close()  # 大量画像データ処理によるメモリ不足エラーを避ける．\n",
    "        self.count += 1  # 保存用ナンバーの更新\n",
    "        \n",
    "        # 散布図作成・保存メソッド(line)\n",
    "    def plotGraph(self, scatterLabels, figName, logFlag, *args):  #\n",
    "        # scatterLabels:グラフタイトル,x軸タイトル、y軸タイトル, figName：参照メソッドに関連する名前, logFlag:対数グラフ化のフラグ\n",
    "        # args:(各次元のlogデータ,timeデータ,手法名)のデータセット\n",
    "\n",
    "        # ---グラフ設定----\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 9))  # 拡張性確保のためにsubplotで生成．\n",
    "        plt.subplots_adjust(bottom=0.15)  # グラフの下部空白を拡張\n",
    "\n",
    "        # ---対数グラフ化----\n",
    "        if logFlag:\n",
    "#            ax.set_yscale('log')\n",
    "            ax.set_xscale('log')\n",
    "\n",
    "        # ----グラフ作成-----\n",
    "        # グラフに写像するデータの種類分だけループ\n",
    "        for i in range(len(args)):\n",
    "            ax.plot(args[i][0], args[i][1], label=args[i][2], linestyle=self.lineStyle[i])  # 散布図を作成\n",
    "        ax.set_title(scatterLabels[0], y=-.2)  # タイトル設定、枠外下部に来るように調整\n",
    "        ax.set_xlabel(scatterLabels[1])  # x軸ラベルの設定、枠外下部に来るように調整\n",
    "        ax.set_ylabel(scatterLabels[2])  # y軸ラベルの設定、枠外左部に来るように調整\n",
    "        plt.grid()  # グリッドを追加\n",
    "        ax.legend(loc='lower right')  # 凡例の位置を設定\n",
    "        # plt.show()\n",
    "\n",
    "        # ---グラフの保存---\n",
    "        fig.savefig(f\"{self.saveDirectory}scatter{self.count}_{figName}.png\")  # 画像の保存\n",
    "        plt.close()  # 大量画像データ処理によるメモリ不足エラーを避ける．\n",
    "        self.count += 1  # 保存用ナンバーの更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divPrint(*args):  # 任意の数の変数を開業しながら表示。開始と終了を線で区切る。\n",
    "    print(\"===========================================================\\n\")\n",
    "    for i in args:\n",
    "        print(f\"{i}\\n\")\n",
    "    print(\"\\n===========================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN(nn.Module): # 自分のNNモデルを nn.Moduleのサブクラスとして定義\n",
    "    def __init__(self, hiddenLayerNulonNum=200): # コンストラクタ\n",
    "        super(MyNN, self).__init__() # 上位クラスのコンストラクタを継承\n",
    "        self.fc1 = nn.Linear(in_features=28*28,out_features=hiddenLayerNulonNum) # 全結合 28*28→200\n",
    "        self.fc2 = nn.Linear(in_features=hiddenLayerNulonNum,out_features=10)    # 全結合 200→10(0～9の十種類)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.bnorm = nn.BatchNorm1d(200)\n",
    "    \n",
    "    def forward(self,x): # 入力に対する結果を返すNNの定義。backwardは自動的に定義される\n",
    "        # xのデータ構造を (バッチサイズ, 1, 28, 28) → (バッチサイズ, 28*28)に変換\n",
    "        x = x.view(-1,28*28)\n",
    "        # 入力層→中間層\n",
    "        x = self.fc1(x)\n",
    "        # 活性化関数 relu(x)=max(0,x)\n",
    "        # x = F.relu(x)CrossEntropyLoss\n",
    "        # 活性化関数 シグモイド\n",
    "        x = torch.sigmoid(x)\n",
    "        # 中間層→出力層\n",
    "        output = self.fc2(x)\n",
    "        #output = F.softmax(output, dim=1) # 通常はsoftmaxが必要だが、PyTorchではCrossEntropyにsoftmaxが入ってるので不要\n",
    "        \n",
    "        return output\n",
    "    \n",
    "class MyCNN(nn.Module): # 5層CNNのクラス\n",
    "    def __init__(self): # コンストラクタ\n",
    "        super(MyCNN,self).__init__() # 上位クラスのコンストラクタを継承\n",
    "        self.firstSize = 128\n",
    "        self.sizes =[self.firstSize, self.firstSize*2, self.firstSize*8]\n",
    "        self.conv1 = nn.Conv2d(1, self.sizes[0], 5) # 28x28x1 -> 24x24x256 (kernel:5)\n",
    "        self.pool = nn.MaxPool2d(2, 2) # 24x24x256 -> 12x12x256, 8x8x512 -> 4x4x512\n",
    "        self.conv2 = nn.Conv2d(self.sizes[0], self.sizes[1], 5) # 12x12x256 -> 8x8x512 (kernel:5)\n",
    "        self.fc1 = nn.Linear(in_features=4*4*self.sizes[1],out_features=self.sizes[2]) # 全結合 4x4x512→2048\n",
    "        self.fc2 = nn.Linear(in_features=self.sizes[2],out_features=10)    # 全結合 2048→10(0～9の十種類)\n",
    "        \n",
    "    \n",
    "    def forward(self,x): # 入力に対する結果を返すNNの定義。backwardは自動的に定義される\n",
    "        # 入力層→中間層1\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = torch.relu(x)\n",
    "        # 中間層1→中間層2\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = torch.relu(x)\n",
    "        # 中間層2→中間層3\n",
    "        # xのデータ構造を (バッチサイズ, 4, 4, 64) → (バッチサイズ, 4x4x64)に変換\n",
    "        x = x.view(-1,4*4*self.sizes[1])\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        # 中間層3→出力層\n",
    "        output = self.fc2(x)\n",
    "        #output = F.softmax(output, dim=1) # 通常はsoftmaxが必要だが、PyTorchではCrossEntropyにsoftmaxが入ってるので不要\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, objective, optimizer, epoch, device):\n",
    "    # \n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for count, (data, target) in enumerate(loader):\n",
    "        \n",
    "        data = data.to(device) # GPUを使用するため，to()で明示的に指定\n",
    "        target = target.to(device) # 同上\n",
    "#        print(data.device, target.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = objective(output,target) # 損失(CrossEntropy)を計算     \n",
    "        total_loss += loss\n",
    "        \n",
    "        loss.backward() # 誤差逆伝播\n",
    "        optimizer.step()\n",
    "        if ((count+1)%100==0):\n",
    "            print(\"[%d] loss=%g\"%((count+1),loss))\n",
    "    print(\"Average loss = %g\"%(total_loss/(count+1)) )\n",
    "    \n",
    "def test(model, loader, objective, device):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for count, (data, target) in enumerate(loader):\n",
    "            \n",
    "            data = data.to(device) # GPUを使用するため，to()で明示的に指定\n",
    "            target = target.to(device) # 同上\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = objective(output,target) # 損失(交差エントロピー)を計算     \n",
    "            total_loss += loss\n",
    "            _, predicted = torch.max(output.data,1)\n",
    "            correct += (predicted==target).sum().item() # sumの結果はテンソル\n",
    "            total += target.size(0)\n",
    "        accuracy = correct/total\n",
    "    print(\"loss = %g, accuracy = %g\"%(total_loss/(count+1),accuracy*100) )\n",
    "    return accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # GPUの設定（PyTorchでは明示的に指定する必要がある）\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"device=\", device)\n",
    "    \n",
    "    bsize=64\n",
    "\n",
    "    # 学習データダウンロード\n",
    "    trainval_set = datasets.MNIST('./data', train=True, download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ]))\n",
    "\n",
    "    # テストデータダウンロード\n",
    "    test_set = datasets.MNIST('./data', train=False, \n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ]))\n",
    "\n",
    "    train_size = int(len(trainval_set)*0.9)\n",
    "    validation_size = len(trainval_set)-train_size\n",
    "    train_set, validation_set = torch.utils.data.random_split(trainval_set, [train_size,validation_size] )\n",
    "\n",
    "    print(\"train_set: \", type(train_set), len(train_set))\n",
    "    print(\"validation_set: \", type(validation_set), len(validation_set))\n",
    "    print(\"test_set: \", type(test_set), len(test_set))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=bsize, shuffle=True )\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(\n",
    "        validation_set, batch_size=bsize, shuffle=True )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_set, batch_size=bsize, shuffle=True )\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        print(\"Batch shape: \",data.size())\n",
    "        break\n",
    "\n",
    "    # 3層ニューラルネットのオブジェクトを生成\n",
    "    setmodel = MyNN(hiddenLayerNulonNum=1000)\n",
    "    mymodels = [setmodel.to(device)]\n",
    "    # 5層畳み込みニューラルネットのオブジェクトを生成\n",
    "    setmodel = MyCNN()\n",
    "    mymodels.append(setmodel.to(device))\n",
    "    print(\"Defined models=\",mymodels)\n",
    "    objective = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # 5層CNNと3層NNの精度検証用の変数の定義        \n",
    "    netName=[\"3layers-NN\", \"5layers-CNN\"]\n",
    "    dataSet=[]\n",
    "    graph=Graph()\n",
    "    maxEpoch=200\n",
    "    divPrint(\"max Epoch\",maxEpoch)\n",
    "    lr=0.1  # 3層NNの学習率\n",
    "\n",
    "    # mymodelをmymodelsの要素で設定し，学習を実施．\n",
    "    for mymodel, network in zip(mymodels, netName):\n",
    "        # 最適化手法いろいろ\n",
    "        if network==\"5layers-CNN\":\n",
    "            lr=0.001  # 5層CNNの学習率\n",
    "        optimizer = optim.SGD(mymodel.parameters(), lr=lr, momentum=0.9)\n",
    "    #     optimizerSet.append(optim.RMSprop(mymodel.parameters()))\n",
    "    #     optimizerSet.append(optim.Adadelta(mymodel.parameters()))\n",
    "    #     optimizerSet.append(optim.Adagrad(mymodel.parameters()))\n",
    "    #     optimizerSet.append(optim.Adam(mymodel.parameters()))\n",
    "    \n",
    "        accuracySet = []\n",
    "        epochSet = []\n",
    "        divPrint(\"Network\", network)\n",
    "        for epoch in range(1, maxEpoch+1):\n",
    "            print(\"--- Epoch %d ---\"%epoch)\n",
    "            train(mymodel, train_loader, objective, optimizer, epoch, device)\n",
    "            print(\"Validation --> \", end=\"\")\n",
    "            test(mymodel, validation_loader, objective, device)\n",
    "            print(\"Test --> \", end=\"\")\n",
    "            accuracy=test(mymodel, test_loader, objective, device)\n",
    "            epochSet.append(epoch)\n",
    "            accuracySet.append(accuracy)\n",
    "        dataSet.append([epochSet, accuracySet, network])\n",
    "        divPrint(\"Network\", network,\"epoch\",epoch,\"accuracy\",accuracy)\n",
    "        \n",
    "    # グラフの出力        \n",
    "    scatterLabels=[\"epoch-accuracy(Networks)\", \"epoch\", \"accuracy [%]\"]\n",
    "    divPrint(*dataSet)\n",
    "    graph.plotGraph(scatterLabels, \"Epoch-accuracy(Networks)\", True, *dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}